import os
import random
import numpy as np
import torch
from collections import defaultdict

from ZJHEnvMulti2to9 import ZJHEnvMulti2to9
from agent_a30 import A30Agent
from zjh_opponents_multi import (
    NitOpponent,
    LooseOpponent,
    AggroOpponent,
    FishOpponent,
    TAGOpponent,
    ManiacOpponent,
    GTOOpponent,
)

# ============================================================
# Action Mask（与训练 / 服务 / agent 完全一致）
# ============================================================

def build_action_mask(env):
    mask = [1] * env.action_dim
    hero = env.players[0]

    # 第一轮禁止 PK
    if env.round_index == 0:
        mask[12] = 0

    # 已看牌不能再 LOOK
    if hero["has_seen"]:
        mask[1] = 0

    # 最低下注倍数
    min_unit = env._min_required_unit(hero)
    min_pay = min_unit * env.ante_bb * (2 if hero["has_seen"] else 1)

    if hero["stack_bb"] < min_pay:
        for a in range(2, 12):
            mask[a] = 0
    else:
        for a in range(2, 12):
            if (a - 1) < min_unit:
                mask[a] = 0

    return np.array(mask, dtype=np.float32)


# ============================================================
# 对手池（固定顺序，保证可复现）
# ============================================================

OPPONENT_POOL = [
    NitOpponent(),
    LooseOpponent(),
    AggroOpponent(),
    FishOpponent(),
    TAGOpponent(),
    ManiacOpponent(),
    GTOOpponent(),
]


def sample_opponents(env):
    """
    固定但随机（可控）
    """
    opponents = [None]
    for _ in range(env.max_players - 1):
        opponents.append(random.choice(OPPONENT_POOL))
    return opponents


# ============================================================
# Evaluation
# ============================================================

def evaluate(
    model_path: str,
    num_episodes: int = 2000,
    seed: int = 42,
):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    env = ZJHEnvMulti2to9(
        min_players=2,
        max_players=9,
        max_round=20,
    )

    agent = A30Agent(
        state_dim=env.state_dim,
        action_dim=env.action_dim,
        device=device,
    )
    agent.load(model_path)
    agent.epsilon = 0.0  # exploit only

    # 统计
    stats = defaultdict(float)
    action_counter = defaultdict(int)

    total_reward = 0.0

    for ep in range(1, num_episodes + 1):
        state = env.reset()
        env.bind_opponents(sample_opponents(env))

        done = False
        ep_reward = 0.0

        while not done:
            mask = build_action_mask(env)
            action = agent.select_action(state, mask)

            action_counter[action] += 1

            next_state, reward, done, _ = env.step(action)
            state = next_state
            ep_reward += reward

        total_reward += ep_reward

        # 结果分类
        if ep_reward > 0:
            stats["win"] += 1
        elif ep_reward < 0:
            stats["lose"] += 1
        else:
            stats["draw"] += 1

        stats["total_pot"] += env.pot_bb
        stats["total_contrib"] += env.hero_contrib_bb

        if ep % 200 == 0:
            print(f"[EVAL] {ep}/{num_episodes} episodes")

    # ========================================================
    # 汇总
    # ========================================================

    avg_reward = total_reward / num_episodes
    win_rate = stats["win"] / num_episodes

    print("\n================ Evaluation Result ================\n")
    print(f"Model          : {model_path}")
    print(f"Episodes       : {num_episodes}")
    print(f"Win Rate       : {win_rate:.4f}")
    print(f"Avg Reward     : {avg_reward:.4f} BB")
    print(f"Avg Pot        : {stats['total_pot'] / num_episodes:.2f} BB")
    print(f"Avg Contrib    : {stats['total_contrib'] / num_episodes:.2f} BB")

    print("\nAction Distribution:")
    total_actions = sum(action_counter.values())
    for a in sorted(action_counter.keys()):
        ratio = action_counter[a] / max(1, total_actions)
        print(f"  Action {a:2d}: {ratio:.3%}")

    print("\n===================================================\n")


# ============================================================
# Entry
# ============================================================

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--model", type=str, required=True, help="model path")
    parser.add_argument("--episodes", type=int, default=2000)
    parser.add_argument("--seed", type=int, default=42)

    args = parser.parse_args()

    evaluate(
        model_path=args.model,
        num_episodes=args.episodes,
        seed=args.seed,
    )
