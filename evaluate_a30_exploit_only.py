# evaluate_a30_exploit_only.py
# A30 Exploit-only 评估脚本（已适配 ZJHEnvMulti14_8p.bind_opponents）

import time
import argparse
import numpy as np
import torch

from agent_a30 import a30Agent
from config_a30_hybrid import A30ConfigHybrid

# ====== 对手 ======
from zjh_opponents_multi import (
    NitOpponent,
    LooseOpponent,
    AggroOpponent,
    FishOpponent,
    TAGOpponent,
    GTOOpponent,
    ManiacOpponent,
)

OPPONENTS = [
    NitOpponent,
    LooseOpponent,
    AggroOpponent,
    FishOpponent,
    TAGOpponent,
    GTOOpponent,
    ManiacOpponent,
]


# ====== 环境（关键修改点在这里） ======
def make_env(opponent_cls):
    from ZJHEnvMulti2to9 import ZJHEnvMulti2to9

    env = ZJHEnvMulti2to9(
        max_round=20,
        min_players=3,
        max_players=8
    )

    # ===== 关键：绑定 opponents =====
    opponents = [None]  # index 0 = Hero
    for _ in range(1, env.max_players):
        opponents.append(opponent_cls())

    env.bind_opponents(opponents)

    return env


# ====== Exploit-only 核心评估 ======
@torch.no_grad()
def evaluate_exploit_only(
    agent: a30Agent,
    opponent_cls,
    episodes: int,
    n_envs: int,
    device: str,
):
    net = agent.eval_net.to(device)
    net.eval()   # ★ Exploit-only：关闭 NoisyNet

    envs = [make_env(opponent_cls) for _ in range(n_envs)]
    states = [env.reset() for env in envs]

    action_dim = agent.cfg.action_dim
    action_counts = [0] * action_dim

    ep_returns = []
    cur_returns = [0.0] * n_envs
    finished = 0

    t0 = time.time()

    while finished < episodes:
        st = torch.tensor(np.asarray(states), dtype=torch.float32, device=device)
        q = net(st)
        actions = torch.argmax(q, dim=1).tolist()

        next_states = states[:]

        for i, env in enumerate(envs):
            a = actions[i]
            action_counts[a] += 1

            ns, r, done, _ = env.step(a)
            cur_returns[i] += r

            if done:
                ep_returns.append(cur_returns[i])
                finished += 1
                cur_returns[i] = 0.0

                if finished >= episodes:
                    break

                ns = env.reset()

            next_states[i] = ns

        states = next_states

    elapsed = time.time() - t0
    arr = np.asarray(ep_returns, dtype=np.float32)

    return {
        "opponent": opponent_cls.__name__,
        "episodes": episodes,
        "mean_ev": float(arr.mean()),
        "std_ev": float(arr.std()),
        "min_ev": float(arr.min()),
        "max_ev": float(arr.max()),
        "action_counts": action_counts,
        "elapsed_sec": elapsed,
        "eps_per_sec": episodes / elapsed
    }


# ====== 主入口 ======
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--ckpt", type=str, required=True)
    parser.add_argument("--episodes", type=int, default=20000)
    parser.add_argument("--n_envs", type=int, default=32)
    parser.add_argument("--device", type=str, default="auto")
    args = parser.parse_args()

    device = "cuda" if args.device == "auto" and torch.cuda.is_available() else "cpu"

    ckpt = torch.load(args.ckpt, map_location="cpu")
    cfg = A30ConfigHybrid(**ckpt["cfg"])
    cfg.device = device

    agent = a30Agent(cfg)
    agent.load(args.ckpt)

    print(f"[Exploit-only Eval] device={device}, n_envs={args.n_envs}")

    for opp in OPPONENTS:
        res = evaluate_exploit_only(
            agent,
            opponent_cls=opp,
            episodes=args.episodes,
            n_envs=args.n_envs,
            device=device
        )

        print(f"\n===== VS {res['opponent']} =====")
        print(f"EV      : {res['mean_ev']:.6f} ± {res['std_ev']:.6f}")
        print(f"min/max : {res['min_ev']:.6f} / {res['max_ev']:.6f}")
        print(f"speed   : {res['eps_per_sec']:.2f} eps/s")
        print("actions :")
        for i, c in enumerate(res["action_counts"]):
            print(f"  a{i:02d}: {c}")


if __name__ == "__main__":
    main()
